{"cells":[{"cell_type":"markdown","metadata":{"id":"e1_Y75QXJS6h"},"source":["## TensorFlow 및 기타 라이브러리 가져오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YfIk2es3hJEd"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, losses\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Model"]},{"cell_type":"markdown","metadata":{"id":"iYn4MdZnKCey"},"source":["## 데이터세트 로드하기\n","\n","시작하려면 Fashon MNIST 데이터세트를 사용하여 기본 autoencoder를 훈련합니다. 이 데이터세트의 각 이미지는 28x28 픽셀입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZm503-I_tji"},"outputs":[],"source":["(x_train, _), (x_test, _) = fashion_mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","print (x_train.shape)\n","print (x_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MUxidpyChjX"},"outputs":[],"source":["latent_dim = 64\n","\n","class Autoencoder(Model):\n","  def __init__(self, latent_dim):\n","    super(Autoencoder, self).__init__()\n","    self.latent_dim = latent_dim\n","    self.encoder = tf.keras.Sequential([\n","      layers.Flatten(),\n","      layers.Dense(latent_dim, activation='relu'),\n","    ])\n","    self.decoder = tf.keras.Sequential([\n","      layers.Dense(784, activation='sigmoid'),\n","      layers.Reshape((28, 28))\n","    ])\n","\n","  def call(self, x):\n","    encoded = self.encoder(x)\n","    decoded = self.decoder(encoded)\n","    return decoded\n","\n","autoencoder = Autoencoder(latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9I1JlqEIDCI4"},"outputs":[],"source":["autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"]},{"cell_type":"markdown","metadata":{"id":"7oJSeMTroABs"},"source":["`x_train`을 입력과 대상으로 사용하여 모델을 훈련합니다. `encoder`는 데이터세트를 784차원에서 잠재 공간으로 압축하는 방법을 배우고, `decoder`는 원본 이미지를 재구성하는 방법을 배웁니다. ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1RI9OfHDBsK"},"outputs":[],"source":["autoencoder.fit(x_train, x_train,\n","                epochs=10,\n","                shuffle=True,\n","                validation_data=(x_test, x_test))"]},{"cell_type":"markdown","metadata":{"id":"wAM1QBhtoC-n"},"source":["모델이 훈련되었으므로 테스트 세트에서 이미지를 인코딩 및 디코딩하여 테스트해 보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pbr5WCj7FQUi"},"outputs":[],"source":["encoded_imgs = autoencoder.encoder(x_test).numpy()\n","decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4LlDOS6FUA1"},"outputs":[],"source":["n = 10\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","  # display original\n","  ax = plt.subplot(2, n, i + 1)\n","  plt.imshow(x_test[i])\n","  plt.title(\"original\")\n","  plt.gray()\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","\n","  # display reconstruction\n","  ax = plt.subplot(2, n, i + 1 + n)\n","  plt.imshow(decoded_imgs[i])\n","  plt.title(\"reconstructed\")\n","  plt.gray()\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDYHJA2PCQ3m"},"outputs":[],"source":["(x_train, _), (x_test, _) = fashion_mnist.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJZ-TcaqDBr5"},"outputs":[],"source":["x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","x_train = x_train[..., tf.newaxis]\n","x_test = x_test[..., tf.newaxis]\n","\n","print(x_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"aPZl_6P65_8R"},"source":["이미지에 임의의 노이즈를 추가합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axSMyxC354fc"},"outputs":[],"source":["noise_factor = 0.2\n","x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape)\n","x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape)\n","\n","x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n","x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"]},{"cell_type":"markdown","metadata":{"id":"wRxHe4XXltNd"},"source":["노이즈가 있는 이미지를 플롯합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thKUmbVVCQpt"},"outputs":[],"source":["n = 10\n","plt.figure(figsize=(20, 2))\n","for i in range(n):\n","    ax = plt.subplot(1, n, i + 1)\n","    plt.title(\"original + noise\")\n","    plt.imshow(tf.squeeze(x_test_noisy[i]))\n","    plt.gray()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Sy9SY8jGl5aP"},"source":["### 컨볼루셔널 autoencoder 정의하기"]},{"cell_type":"markdown","metadata":{"id":"vT_BhZngWMwp"},"source":["이 예제에서는 <code>encoder</code>에 <a>Conv2D</a> 레이어를 사용하고 <code>decoder</code>에 <a>Conv2DTranspose</a> 레이어를 사용하여 컨볼루셔널 autoencoder를 훈련합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R5KjoIlYCQko"},"outputs":[],"source":["class Denoise(Model):\n","  def __init__(self):\n","    super(Denoise, self).__init__()\n","    self.encoder = tf.keras.Sequential([\n","      layers.Input(shape=(28, 28, 1)),\n","      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n","      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n","\n","    self.decoder = tf.keras.Sequential([\n","      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n","      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n","      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n","\n","  def call(self, x):\n","    encoded = self.encoder(x)\n","    decoded = self.decoder(encoded)\n","    return decoded\n","\n","autoencoder = Denoise()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYKbiDFYCQfj"},"outputs":[],"source":["autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IssFr1BNCQX3"},"outputs":[],"source":["autoencoder.fit(x_train_noisy, x_train,\n","                epochs=10,\n","                shuffle=True,\n","                validation_data=(x_test_noisy, x_test))"]},{"cell_type":"markdown","metadata":{"id":"G85xUVBGTAKp"},"source":["encoder의 요약을 살펴보겠습니다. 이미지가 28x28에서 7x7로 어떻게 다운샘플링되는지 확인하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oEpxlX6sTEQz"},"outputs":[],"source":["autoencoder.encoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"DDZBfMx1UtXx"},"source":["decoder는 이미지를 7x7에서 28x28로 다시 업샘플링합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbeQtYMaUpro"},"outputs":[],"source":["autoencoder.decoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"A7-VAuEy_N6M"},"source":["autoencoder에서 생성된 노이즈가 있는 이미지와 노이즈가 제거 된 이미지를 모두 플롯합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5IyPi1fCQQz"},"outputs":[],"source":["encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\n","decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sfxr9NdBCP_x"},"outputs":[],"source":["  n = 10\n","  plt.figure(figsize=(20, 4))\n","  for i in range(n):\n","\n","      # display original + noise\n","      ax = plt.subplot(2, n, i + 1)\n","      plt.title(\"original + noise\")\n","      plt.imshow(tf.squeeze(x_test_noisy[i]))\n","      plt.gray()\n","      ax.get_xaxis().set_visible(False)\n","      ax.get_yaxis().set_visible(False)\n","\n","      # display reconstruction\n","      bx = plt.subplot(2, n, i + n + 1)\n","      plt.title(\"reconstructed\")\n","      plt.imshow(tf.squeeze(decoded_imgs[i]))\n","      plt.gray()\n","      bx.get_xaxis().set_visible(False)\n","      bx.get_yaxis().set_visible(False)\n","  plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/generative/autoencoder.ipynb","timestamp":1701253286007}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}